{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp-UaomMQJNo"
   },
   "source": [
    "# Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBhbug0Qgmuu"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, we will use what we covered in [`0-autoencoder.ipynb`](0-autoencoder.ipynb) regarding autoencoder, and use it for denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zK2SZnszhSYk"
   },
   "source": [
    "## Setup\n",
    "Let's start by importing the libraries and functions that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1sepk9uMddm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n",
      "Is Executing Eagerly? True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "__version__ = '1.0.0'\n",
    "__author__ = 'Abien Fred Agarap'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Is Executing Eagerly?', tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CH3QqWQ1RiP2"
   },
   "source": [
    "## Autoencoder model\n",
    "\n",
    "An autoencoder consists of two components: (1) an **encoder** which learns the data representation $z$, i.e. the important features of a given data $x$ (I like to describe it as _what makes something something_), and (2) a **decoder** which outputs a reconstruction of the data $\\hat{x}$ based on its idea $z$ of how the original data $x$ is structured.\n",
    "$$ z = f\\big(h_{e}(x)\\big)$$\n",
    "$$ \\hat{x} = f\\big(h_{d}(z)\\big)$$\n",
    "where $z$ is the learned data representation by encoder $h_{e}$, and $\\hat{x}$ is the reconstructed data by decoder $h_{d}$ based on $z$.\n",
    "\n",
    "Let's further dissect the model below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fiYJ9BLW-w40"
   },
   "source": [
    "### Define an encoder layer\n",
    "\n",
    "The first component, the **encoder**, is similar to a conventional feed-forward network. However, it is not tasked on predicting values (a _regression_ task) or categories (a _classification_ task). Instead, it is tasked to learn how the data is structured, i.e. data representation $z$. We can implement the encoder layer as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdl5_0Z4-w41"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, intermediate_dim=128, code_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_layer = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=code_dim, activation=tf.nn.sigmoid)\n",
    "    \n",
    "    def call(self, input_features):\n",
    "        activation = self.hidden_layer(input_features)\n",
    "        return self.output_layer(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WgR-V0--w44"
   },
   "source": [
    "The _encoding_ is done by passing data input $x$ to the encoder's hidden layer $h$ in order to learn the data representation $z = f(h(x))$.\n",
    "\n",
    "We first write an `Encoder` class that inherits the [`tf.keras.layers.Layer`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) class to define it as a layer. So, why a layer instead of a model? Recall that the encoder is a _component_ of the autoencoder model.\n",
    "\n",
    "Analyzing the code, the `Encoder` layer is defined to have a single hidden layer of neurons (`self.hidden_layer`) to learn the input features. Then, we connect the hidden layer to a layer (`self.output_layer`) that encodes the learned activations to lower dimension which consists of what it thinks as important features. Hence, the \"output\" of the `Encoder` layer is the _what makes something something_ $z$ of the data $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9me1ZLq-w45"
   },
   "source": [
    "### Define a decoder layer\n",
    "\n",
    "The second component, the **decoder**, is also similar to a feed-forward network. However, instead of reducing data to lower dimension, it attempts to reverse the process, i.e. reconstruct the data from its lower dimension representation $z$ to its original dimension.\n",
    "\n",
    "The _decoding_ is done by passing the lower dimension representation $z$ to the decoder's hidden layer $h$ in order to reconstruct the data to its original dimension $\\hat{x} = f(h(z))$. We can implement the decoder layer as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3za66lwMjWX"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, original_dim, code_dim=64):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_layer = tf.keras.layers.Dense(units=code_dim, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=original_dim, activation=tf.nn.sigmoid)\n",
    "  \n",
    "    def call(self, code):\n",
    "        activation = self.hidden_layer(code)\n",
    "        return self.output_layer(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SU-QtEUo-w4-"
   },
   "source": [
    "We now write a `Decoder` class that also inherits the `tf.keras.layers.Layer`.\n",
    "\n",
    "The `Decoder` layer is also defined to have a single hidden layer of neurons to reconstruct the input features $\\hat{x}$ from the learned representation $z$ by the encoder $f\\big(h_{e}(x)\\big)$. Then, we connect its hidden layer to a layer that decodes the data representation from lower dimension $z$ to its original dimension $\\hat{x}$. Hence, the \"output\" of the `Decoder` layer is the reconstructed data $\\hat{x}$ from the data representation $z$.\n",
    "\n",
    "Ultimately, the output of the decoder is the autoencoder's output.\n",
    "\n",
    "Now that we have defined the components of our autoencoder, we can finally build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZRIHpkl-w5A"
   },
   "source": [
    "### Build the autoencoder model\n",
    "\n",
    "We can now build the autoencoder model by instantiating `Encoder` and `Decoder` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rl5HUez7-w5C"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, intermediate_dim, code_dim, original_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.loss = []\n",
    "        self.encoder = Encoder(intermediate_dim=intermediate_dim, code_dim=code_dim)\n",
    "        self.decoder = Decoder(code_dim=code_dim, original_dim=original_dim)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        code = self.encoder(input_features)\n",
    "        reconstructed = self.decoder(code)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25zYoLju-w5G"
   },
   "source": [
    "As discussed above, the encoder's output is the input to the decoder, as it is written above (`reconstructed = self.decoder(code)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9NBnWhSnvn4"
   },
   "source": [
    "### Reconstruction error\n",
    "\n",
    "We only discussed and built the model, but we talked about how it actually learns. All we know up to this point is the _flow of learning_ from the input layer of the encoder which supposedly learns the data representation, and use that representation as input to the decoder that reconstructs the original data.\n",
    "Like \"simple\" neural networks, an autoencoder learns through [backpropagation](https://www.youtube.com/watch?v=LOc_y67AzCA). However, instead of comparing the values or labels of the model, we compare the reconstructed data and the original data. Let's call this comparison the reconstruction error function, and it is given by the following equation,\n",
    "$$ L = \\dfrac{1}{n} \\sum_{i=0}^{n-1} \\big(\\hat{x}_{i} - x_{i}\\big)^{2}$$\n",
    "where $\\hat{x}$ is the reconstructed data while $x$ is the original data.\n",
    "\n",
    "We can implement it as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmWZG-1qLP8p"
   },
   "outputs": [],
   "source": [
    "def loss(reconstructed, original):\n",
    "    return tf.reduce_mean(tf.square(tf.subtract(reconstructed, original)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVjT6C2SqmH0"
   },
   "source": [
    "### Forward pass and optimization\n",
    "\n",
    "We will write a function for computing the forward pass, and applying a chosen optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNSJqjY7qnCe"
   },
   "outputs": [],
   "source": [
    "def train(loss, model, opt, original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstructed = model(original)\n",
    "        reconstruction_error = loss(reconstructed, original)\n",
    "    gradients = tape.gradient(reconstruction_error, model.trainable_variables)\n",
    "    gradient_variables = zip(gradients, model.trainable_variables)\n",
    "    opt.apply_gradients(gradient_variables)\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8c4bNlGLrd5T"
   },
   "source": [
    "### The training loop\n",
    "\n",
    "Finally, we will write a function to run the training loop. This function will take arguments for the model, the optimization function, the loss, the dataset, and the training epochs.\n",
    "\n",
    "The training loop itself uses a `GradientTape` context defined in `train` for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8Sh1UaQrc5D"
   },
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss, dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_features in dataset:\n",
    "            loss_values = train(loss, model, opt, batch_features)\n",
    "            epoch_loss += loss_values\n",
    "        model.loss.append(tf.reduce_mean(epoch_loss))\n",
    "        print('Epoch {}/{}. Loss: {}'.format(epoch + 1, epochs, tf.reduce_mean(epoch_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eCxbz9ZSwjr"
   },
   "source": [
    "### Process the dataset\n",
    "\n",
    "Now that we have defined our `Autoencoder` class, the loss function, and the training loop, let's import the dataset. We will normalize the pixel values for each example through dividing by maximum pixel value. We shall flatten the examples from 28 by 28 arrays to 784-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAN1ONp6MvI7"
   },
   "outputs": [],
   "source": [
    "(training_features, _), (test_features, _) = mnist.load_data()\n",
    "\n",
    "training_features = training_features.astype('float32') / 255.\n",
    "test_features = test_features.astype('float32') / 255.\n",
    "\n",
    "training_features += tf.random.normal(stddev=5e-2, shape=training_features.shape)\n",
    "test_features += tf.random.normal(stddev=5e-2, shape=test_features.shape)\n",
    "\n",
    "training_features = training_features.reshape(training_features.shape[0], 784)\n",
    "test_features = test_features.reshape(test_features.shape[0], 784)\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(training_features)\n",
    "training_dataset = training_dataset.prefetch(4096)\n",
    "training_dataset = training_dataset.shuffle(training_features.shape[0])\n",
    "training_dataset = training_dataset.batch(128, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "268qdJGGTULP"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Now, all we have to do is instantiate the autoencoder model and choose an optimization function, then pass the intermediate dimension and the original dimension of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8nw7mdKMxvb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100. Loss: 24.58465003967285\n",
      "Epoch 2/100. Loss: 12.778584480285645\n",
      "Epoch 3/100. Loss: 9.938030242919922\n",
      "Epoch 4/100. Loss: 8.548629760742188\n",
      "Epoch 5/100. Loss: 7.863142967224121\n",
      "Epoch 6/100. Loss: 7.4014997482299805\n",
      "Epoch 7/100. Loss: 7.0308918952941895\n",
      "Epoch 8/100. Loss: 6.7640204429626465\n",
      "Epoch 9/100. Loss: 6.610593795776367\n",
      "Epoch 10/100. Loss: 6.525899887084961\n",
      "Epoch 11/100. Loss: 6.405040740966797\n",
      "Epoch 12/100. Loss: 6.370055198669434\n",
      "Epoch 13/100. Loss: 6.298134803771973\n",
      "Epoch 14/100. Loss: 6.250308513641357\n",
      "Epoch 15/100. Loss: 6.235457897186279\n",
      "Epoch 16/100. Loss: 6.215330123901367\n",
      "Epoch 17/100. Loss: 6.11767053604126\n",
      "Epoch 18/100. Loss: 6.017238616943359\n",
      "Epoch 19/100. Loss: 5.956178188323975\n",
      "Epoch 20/100. Loss: 5.871927738189697\n",
      "Epoch 21/100. Loss: 5.847806930541992\n",
      "Epoch 22/100. Loss: 5.801619052886963\n",
      "Epoch 23/100. Loss: 5.776648044586182\n",
      "Epoch 24/100. Loss: 5.76164436340332\n",
      "Epoch 25/100. Loss: 5.743459224700928\n",
      "Epoch 26/100. Loss: 5.722104549407959\n",
      "Epoch 27/100. Loss: 5.696108341217041\n",
      "Epoch 28/100. Loss: 5.6900529861450195\n",
      "Epoch 29/100. Loss: 5.707517623901367\n",
      "Epoch 30/100. Loss: 5.651362895965576\n",
      "Epoch 31/100. Loss: 5.647412300109863\n",
      "Epoch 32/100. Loss: 5.640526294708252\n",
      "Epoch 33/100. Loss: 5.607086658477783\n",
      "Epoch 34/100. Loss: 5.634147644042969\n",
      "Epoch 35/100. Loss: 5.601219177246094\n",
      "Epoch 36/100. Loss: 5.5964226722717285\n",
      "Epoch 37/100. Loss: 5.594660758972168\n",
      "Epoch 38/100. Loss: 5.569284915924072\n",
      "Epoch 39/100. Loss: 5.579901695251465\n",
      "Epoch 40/100. Loss: 5.538180828094482\n",
      "Epoch 41/100. Loss: 5.556515216827393\n",
      "Epoch 42/100. Loss: 5.548956871032715\n",
      "Epoch 43/100. Loss: 5.532975196838379\n",
      "Epoch 44/100. Loss: 5.534006118774414\n",
      "Epoch 45/100. Loss: 5.523862361907959\n",
      "Epoch 46/100. Loss: 5.511868000030518\n",
      "Epoch 47/100. Loss: 5.510466575622559\n",
      "Epoch 48/100. Loss: 5.483520030975342\n",
      "Epoch 49/100. Loss: 5.474512100219727\n",
      "Epoch 50/100. Loss: 5.453653335571289\n",
      "Epoch 51/100. Loss: 5.467103958129883\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(intermediate_dim=128, code_dim=64, original_dim=784)\n",
    "opt = tf.optimizers.Adam(learning_rate=1e-2)\n",
    "\n",
    "train_loop(model, opt, loss, training_dataset, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VioflTOhTnwl"
   },
   "source": [
    "## Plot the in-training performance\n",
    "\n",
    "Let's take a look at how the model performed during training in a couple of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azgmhikhM0EE"
   },
   "outputs": [],
   "source": [
    "sns.setstyle('dark', {'grid.linestyle': '--'})\n",
    "plt.plot(range(100), model.loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JccKWvNYTtUW"
   },
   "source": [
    "## Predictions\n",
    "\n",
    "Finally, we will look at some of the predictions. The wrong predictions are labeled in red color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JwpigAlM2dF"
   },
   "outputs": [],
   "source": [
    "number = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for index in range(number):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, number, index + 1)\n",
    "    plt.imshow(test_features[index].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, number, index + 1 + number)\n",
    "    plt.imshow(model(test_features)[index].numpy().reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4rkBaWN-w5r"
   },
   "source": [
    "## Closing remarks\n",
    "\n",
    "As you may see after training this model, the reconstructed images are quite blurry. A number of things could be done to move forward from this point, e.g. adding more layers, or using a convolutional neural network architecture as the basis of the autoencoder, or use a different kind of autoencoder.\n",
    "\n",
    "## References\n",
    "* Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Rafal Jozefowicz, Yangqing Jia, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Mike Schuster, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from [tensorflow.org](https://tensorflow.org/).\n",
    "* Chollet, F. (2016, May 14). Building Autoencoders in Keras. Retrieved March 19, 2019, from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
