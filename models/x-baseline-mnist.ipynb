{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_r_yVCVpS85"
   },
   "source": [
    "Pretraining Autoencoder for Downstream Task\n",
    "=====\n",
    "\n",
    "## Overview \n",
    "\n",
    "In this notebook, we train a neural network with mini VGG layers as a baseline for the experimental mini VGG-based autoencoder + neural network.\n",
    "## Setup \n",
    "\n",
    "We setup our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x8jUvV5leuX"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "__author__ = 'Abien Fred Agarap'\n",
    "__version__ = '1.0.0'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tf.vgg_ae import CAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKkvrPNbpmb8"
   },
   "source": [
    "Set the memory growth of GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfY3Gcevodo7"
   },
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(\n",
    "    tf.config.experimental.list_physical_devices('GPU')[0],\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdguwL96ppDp"
   },
   "source": [
    "Set the random number generator seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MjqEUjAoj4m"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gZK7wlTpq-Y"
   },
   "source": [
    "We set the batch size and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usw0kmm4mLIi"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lq07vmTBps03"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We load the MNIST classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sO1dA2AltFx"
   },
   "outputs": [],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further split the test data into validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features = test_features[:5000]\n",
    "validation_labels = test_labels[:5000]\n",
    "\n",
    "test_features = test_features[5000:]\n",
    "test_labels = test_labels[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8wet1ezpxkh"
   },
   "source": [
    "We preprocess the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmqsR2ORmQ3I"
   },
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(-1, 28, 28, 1)\n",
    "train_features = train_features.astype('float32')\n",
    "train_features = train_features / 255.\n",
    "\n",
    "validation_features = validation_features.reshape(-1, 28, 28, 1)\n",
    "validation_features = validation_features.astype('float32')\n",
    "validation_features = validation_features / 255.\n",
    "\n",
    "test_features = test_features.reshape(-1, 28, 28, 1)\n",
    "test_features = test_features.astype('float32')\n",
    "test_features = test_features / 255.\n",
    "\n",
    "train_labels = tf.one_hot(train_labels, len(np.unique(train_labels)))\n",
    "validation_labels = tf.one_hot(validation_labels, len(np.unique(validation_labels)))\n",
    "test_labels = tf.one_hot(test_labels, len(np.unique(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHbIO76hpzrV"
   },
   "source": [
    "Create the `tf.data.Dataset` object for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOCne-f8nX93"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(batch_size * 4)\n",
    "train_dataset = train_dataset.shuffle(train_features.shape[0])\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels))\n",
    "validation_dataset = validation_dataset.batch(batch_size)\n",
    "validation_dataset = validation_dataset.prefetch(batch_size * 4)\n",
    "validation_dataset = validation_dataset.shuffle(validation_features.shape[0])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels))\n",
    "test_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = train_dataset.prefetch(batch_size * 4)\n",
    "test_dataset = train_dataset.shuffle(test_features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the mini VGG-based autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE(input_shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the encoder component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnvJJEEJqGBt"
   },
   "source": [
    "Build a mini VGG neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "US8to1drmnfj"
   },
   "outputs": [],
   "source": [
    "class NN(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NN, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense_layer = tf.keras.layers.Dense(units=512, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "        \n",
    "    def call(self, features):\n",
    "        activation = self.encoder(features)\n",
    "        activation = self.flatten(activation)\n",
    "        activation = self.dense_layer(activation)\n",
    "        outputs = self.output_layer(activation)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSzliWvXqKCm"
   },
   "source": [
    "Instantiate the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3PVAvJdmo4v"
   },
   "outputs": [],
   "source": [
    "clf = NN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set an early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=1e-4,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FioHPyi9qMzv"
   },
   "source": [
    "Compile the neural network for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7k8qMlelmqui"
   },
   "outputs": [],
   "source": [
    "clf.compile(loss=tf.losses.categorical_crossentropy,\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcVEzQayqQMn"
   },
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "u7DVQwRgmxyG",
    "outputId": "a89f88eb-cd90-4ee0-b2a6-6d6cbdca87a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 - 24s - loss: 2.2643 - accuracy: 0.7297 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "118/118 - 21s - loss: 0.2332 - accuracy: 0.9301 - val_loss: 0.1908 - val_accuracy: 0.9358\n",
      "Epoch 3/100\n",
      "118/118 - 21s - loss: 0.1148 - accuracy: 0.9652 - val_loss: 0.0975 - val_accuracy: 0.9706\n",
      "Epoch 4/100\n",
      "118/118 - 21s - loss: 0.0692 - accuracy: 0.9797 - val_loss: 0.0788 - val_accuracy: 0.9732\n",
      "Epoch 5/100\n",
      "118/118 - 21s - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0743 - val_accuracy: 0.9750\n",
      "Epoch 6/100\n",
      "118/118 - 21s - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0627 - val_accuracy: 0.9804\n",
      "Epoch 7/100\n",
      "118/118 - 21s - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.0561 - val_accuracy: 0.9814\n",
      "Epoch 8/100\n",
      "118/118 - 21s - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.0559 - val_accuracy: 0.9806\n",
      "Epoch 9/100\n",
      "118/118 - 21s - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0548 - val_accuracy: 0.9822\n",
      "Epoch 10/100\n",
      "118/118 - 21s - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0555 - val_accuracy: 0.9816\n",
      "Epoch 11/100\n",
      "118/118 - 21s - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0716 - val_accuracy: 0.9780\n",
      "Epoch 12/100\n",
      "118/118 - 21s - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0510 - val_accuracy: 0.9842\n",
      "Epoch 13/100\n",
      "118/118 - 21s - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0514 - val_accuracy: 0.9836\n",
      "Epoch 14/100\n",
      "118/118 - 21s - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0597 - val_accuracy: 0.9836\n",
      "Epoch 15/100\n",
      "118/118 - 21s - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0580 - val_accuracy: 0.9826\n",
      "Epoch 16/100\n",
      "118/118 - 21s - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0622 - val_accuracy: 0.9828\n",
      "Epoch 17/100\n",
      "118/118 - 21s - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0533 - val_accuracy: 0.9842\n",
      "Epoch 18/100\n",
      "118/118 - 21s - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0561 - val_accuracy: 0.9850\n",
      "Epoch 19/100\n",
      "118/118 - 21s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0564 - val_accuracy: 0.9834\n",
      "Epoch 20/100\n",
      "118/118 - 21s - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
      "Epoch 21/100\n",
      "118/118 - 21s - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0600 - val_accuracy: 0.9842\n",
      "Epoch 22/100\n",
      "118/118 - 21s - loss: 9.1056e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
      "Epoch 23/100\n",
      "118/118 - 21s - loss: 7.3023e-04 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9846\n",
      "Epoch 24/100\n",
      "118/118 - 21s - loss: 4.7245e-04 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9842\n",
      "Epoch 25/100\n",
      "118/118 - 21s - loss: 4.0177e-04 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9848\n",
      "Epoch 26/100\n",
      "118/118 - 21s - loss: 3.4334e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9834\n",
      "Epoch 27/100\n",
      "118/118 - 21s - loss: 3.0441e-04 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9842\n",
      "Epoch 28/100\n",
      "118/118 - 21s - loss: 2.8061e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "history = clf.fit(train_dataset,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=validation_dataset,\n",
    "                  callbacks=[early_stop_callback],\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPER3F84qRck"
   },
   "source": [
    "Evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uVY52Fa2m_x3",
    "outputId": "8a1ac37e-2d46-4bff-b2f2-e764885d453e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 7s - loss: 2.4605e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0002460519570346243, 1.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TFCaAzbqS3w"
   },
   "source": [
    "Perturb the test data with noise from a Normal distribution having a standard deviation of `5e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_OYG3QEnyVj"
   },
   "outputs": [],
   "source": [
    "test_features += tf.random.normal(stddev=5e-2, shape=test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5rqv-Bfqa0p"
   },
   "source": [
    "Evaluate the model on the perturbed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "I7mdvROzn4Lk",
    "outputId": "20662868-89df-46eb-a0e1-0b622f54040f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/1 - 1s - loss: 0.0625 - accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.031710679519176485, 0.9914]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(test_features, test_labels, batch_size=512, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScbIR9owqgyy"
   },
   "source": [
    "Reload the test features, and increase the standard deviation of the Normal distribution from which we shall get the noise from for perturbing the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzmmB4SJoTPZ"
   },
   "outputs": [],
   "source": [
    "_, (test_features, _) = mnist.load_data()\n",
    "\n",
    "test_features = test_features.astype('float32') / 255.\n",
    "test_features = test_features.reshape(-1, 28, 28, 1)\n",
    "test_features += tf.random.normal(stddev=5e-1, shape=test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the last 5000 test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMpQtIYOqtDW"
   },
   "source": [
    "Evaluate on the new perturbed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "B1rpsaLAogbY",
    "outputId": "9f1ae6bb-a692-47bb-b101-fa3679dea94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/1 - 1s - loss: 1.5057 - accuracy: 0.7390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1073272378921508, 0.739]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(test_features, test_labels, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_weights('../assets/export/baseline/mnist/100_epochs', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/export/baseline/mnist/history.txt\", \"w\") as file:\n",
    "    file.write(repr(history.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the saved history later by,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/export/baseline/mnist/history.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "history = eval(data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "x-pretrained-vgg-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
